{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d336966d",
   "metadata": {},
   "source": [
    "\n",
    "# Anomaly Detection POC (Synthetic, Binder-ready) — hack2025\n",
    "\n",
    "This notebook demonstrates anomaly detection on **synthetic time-series** data using:\n",
    "- **Baseline**: Z-score thresholding\n",
    "- **Model**: Isolation Forest (multivariate)\n",
    "- *(Optional)* LSTM Autoencoder (installs `torch` on demand)\n",
    "\n",
    "**Sections**\n",
    "1. Setup\n",
    "2. Generate synthetic time series\n",
    "3. Visualize series & true anomalies\n",
    "4. Baseline: Z-score thresholding\n",
    "5. Isolation Forest (multivariate) + metrics & scores plot\n",
    "6. Prepare data for Streamlit app (persist CSV)\n",
    "7. Create the Streamlit app file\n",
    "8. Launch Streamlit in Binder (proxied)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf0803",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80945141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "print('Environment ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8f1a5",
   "metadata": {},
   "source": [
    "## 2) Generate Synthetic Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "start = datetime(2024, 1, 1)\n",
    "periods = 24 * 90  # 90 days hourly\n",
    "index = [start + timedelta(hours=i) for i in range(periods)]\n",
    "\n",
    "trend = np.linspace(0, 10, periods)\n",
    "daily = 5 * np.sin(2 * np.pi * (np.arange(periods) % 24) / 24)\n",
    "noise = np.random.normal(0, 0.8, periods)\n",
    "value = 50 + trend + daily + noise\n",
    "\n",
    "# Point anomalies\n",
    "anomaly_idx = np.random.choice(np.arange(50, periods-50), size=25, replace=False)\n",
    "value[anomaly_idx] += np.random.choice([15, -15], size=25) + np.random.normal(0, 3, 25)\n",
    "\n",
    "# Contextual anomalies (regime shifts)\n",
    "for start_shift in [1000, 2000]:\n",
    "    value[start_shift:start_shift+48] += 8\n",
    "\n",
    "labels = np.zeros(periods, dtype=int)\n",
    "labels[anomaly_idx] = 1\n",
    "labels[1000:1048] = 1\n",
    "labels[2000:2048] = 1\n",
    "\n",
    "# Extra features\n",
    "feature_temp = 20 + 10*np.sin(2*np.pi*(np.arange(periods)%24)/24) + np.random.normal(0,1,periods)\n",
    "feature_load = 0.3*value + np.random.normal(0,2,periods)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'timestamp': index,\n",
    "    'value': value,\n",
    "    'is_anomaly': labels,\n",
    "    'feature_temp': feature_temp,\n",
    "    'feature_load': feature_load\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ded1b2",
   "metadata": {},
   "source": [
    "## 3) Visualize Series & True Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df['timestamp'], df['value'], label='value')\n",
    "plt.scatter(df['timestamp'][df['is_anomaly']==1], df['value'][df['is_anomaly']==1], s=18, color='red', label='true anomalies')\n",
    "plt.title('Synthetic Time Series with True Anomalies')\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1634048",
   "metadata": {},
   "source": [
    "## 4) Baseline: Z-score Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "series = df['value'].values.astype(float)\n",
    "y_true = df['is_anomaly'].values.astype(int)\n",
    "\n",
    "z = StandardScaler().fit_transform(series.reshape(-1,1)).ravel()\n",
    "z_thresh = 3.0\n",
    "pred_baseline = (np.abs(z) > z_thresh).astype(int)\n",
    "\n",
    "p_b, r_b, f_b, _ = precision_recall_fscore_support(y_true, pred_baseline, average='binary', zero_division=0)\n",
    "print({'precision': p_b, 'recall': r_b, 'f1': f_b})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd4669",
   "metadata": {},
   "source": [
    "## 5) Isolation Forest (Multivariate) + Metrics & Score Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[['value', 'feature_temp', 'feature_load']].values\n",
    "contam = max(1e-3, y_true.mean()+0.01)\n",
    "iso = IsolationForest(n_estimators=200, contamination=contam, random_state=42)\n",
    "iso.fit(X)\n",
    "scores = -iso.score_samples(X)\n",
    "\n",
    "# Threshold using contamination percentile\n",
    "thresh = np.percentile(scores, 100 - 100*contam)\n",
    "pred_iso = (scores >= thresh).astype(int)\n",
    "\n",
    "p_i, r_i, f_i, _ = precision_recall_fscore_support(y_true, pred_iso, average='binary', zero_division=0)\n",
    "print({'precision': p_i, 'recall': r_i, 'f1': f_i})\n",
    "\n",
    "# Plot scores\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df['timestamp'], scores, label='IF anomaly score')\n",
    "plt.axhline(thresh, color='orange', linestyle='--', label='threshold')\n",
    "plt.title('Isolation Forest Anomaly Scores')\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d837d",
   "metadata": {},
   "source": [
    "### Optional: LSTM Autoencoder (on-demand)\n",
    "Run this cell if you want to try a simple LSTM autoencoder. It will install `torch` in-session (not required for Binder build).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment to run (can take a few minutes on Binder)\n",
    "# import sys\n",
    "# try:\n",
    "#     import torch, torch.nn as nn\n",
    "# except Exception:\n",
    "#     !{sys.executable} -m pip -q install torch\n",
    "#     import torch, torch.nn as nn\n",
    "# window = 24\n",
    "# Xw = np.array([series[i:i+window] for i in range(len(series)-window)])\n",
    "# Xw = (Xw - Xw.mean()) / (Xw.std() + 1e-6)\n",
    "# Xw_t = torch.tensor(Xw, dtype=torch.float32).unsqueeze(-1)\n",
    "# class LSTMAE(nn.Module):\n",
    "#     def __init__(self, hidden=16):\n",
    "#         super().__init__()\n",
    "#         self.encoder = nn.LSTM(input_size=1, hidden_size=hidden, batch_first=True)\n",
    "#         self.decoder = nn.LSTM(input_size=hidden, hidden_size=1, batch_first=True)\n",
    "#     def forward(self, x):\n",
    "#         z,_ = self.encoder(x)\n",
    "#         z_last = z[:,-1,:].unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "#         out,_ = self.decoder(z_last)\n",
    "#         return out\n",
    "# model = LSTMAE(hidden=16)\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# loss_fn = nn.MSELoss()\n",
    "# model.train()\n",
    "# for epoch in range(20):\n",
    "#     opt.zero_grad(); out = model(Xw_t)\n",
    "#     loss = loss_fn(out, Xw_t); loss.backward(); opt.step()\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     rec = model(Xw_t)\n",
    "#     err = ((rec - Xw_t)**2).mean(dim=(1,2)).cpu().numpy()\n",
    "# err_series = np.zeros_like(series); err_series[window:] = err\n",
    "# e_thr = np.percentile(err_series[window:], 100 - 100*contam)\n",
    "# pred_lstm = (err_series >= e_thr).astype(int)[:len(y_true)]\n",
    "# p_l, r_l, f_l, _ = precision_recall_fscore_support(y_true, pred_lstm, average='binary', zero_division=0)\n",
    "# print({'precision': p_l, 'recall': r_l, 'f1': f_l})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb60e7",
   "metadata": {},
   "source": [
    "## 6) Prepare data for Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "# Recompute z-score defensively\n",
    "z_score = StandardScaler().fit_transform(df['value'].values.reshape(-1,1)).ravel()\n",
    "# Recompute IF scores defensively\n",
    "X_ = df[['value', 'feature_temp', 'feature_load']].values\n",
    "iso_ = IsolationForest(n_estimators=200, contamination=contam, random_state=42)\n",
    "iso_.fit(X_)\n",
    "if_scores = -iso_.score_samples(X_)\n",
    "\n",
    "# Persist\n",
    "df_out = df.copy()\n",
    "df_out['z_score'] = z_score\n",
    "df_out['if_score'] = if_scores\n",
    "csv_path = 'data/anomaly_results.csv'\n",
    "df_out.to_csv(csv_path, index=False)\n",
    "print('Saved', csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7e7e2",
   "metadata": {},
   "source": [
    "## 7) Create the Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('streamlit_app.py', 'w') as f:\n",
    "    f.write(\"\\nimport streamlit as st\\nimport pandas as pd\\nimport numpy as np\\nimport altair as alt\\nfrom sklearn.metrics import precision_recall_fscore_support\\n\\nst.set_page_config(page_title='Anomaly Detection POC', layout='wide')\\nst.title('Anomaly Detection \\u2014 Synthetic Time Series')\\n\\n@st.cache_data\\ndef load_data():\\n    return pd.read_csv('data/anomaly_results.csv', parse_dates=['timestamp'])\\n\\ndf = load_data()\\n\\nwith st.sidebar:\\n    st.header('Controls')\\n    model = st.selectbox('Model', ['Isolation Forest', 'Z-score'])\\n    if model == 'Isolation Forest':\\n        default_pct = float(max(0.1, (df['is_anomaly'].mean()+0.01)*100))\\n        pct = st.slider('Anomaly rate (percentile threshold)', min_value=0.1, max_value=20.0, value=round(default_pct,2), step=0.1)\\n        thr = np.percentile(df['if_score'], 100 - pct)\\n        pred = (df['if_score'] >= thr).astype(int)\\n        st.caption(f\\\"IF threshold = {thr:.3f} (percentile {100-pct:.1f})\\\")\\n    else:\\n        z_thr = st.slider('Z-score threshold (abs)', min_value=1.0, max_value=5.0, value=3.0, step=0.1)\\n        pred = (np.abs(df['z_score']) >= z_thr).astype(int)\\n        st.caption(f\\\"Z-score |z| \\u2265 {z_thr:.2f}\\\")\\n\\n    show_true = st.checkbox('Show true anomalies', value=True)\\n\\n# Metrics\\ny_true = df['is_anomaly'].astype(int)\\nprecision, recall, f1, _ = precision_recall_fscore_support(y_true, pred, average='binary', zero_division=0)\\ncol1, col2, col3 = st.columns(3)\\ncol1.metric('Precision', f\\\"{precision:.3f}\\\")\\ncol2.metric('Recall', f\\\"{recall:.3f}\\\")\\ncol3.metric('F1', f\\\"{f1:.3f}\\\")\\n\\n# Chart\\nplot_df = df.copy()\\nplot_df['predicted'] = pred\\nbase = alt.Chart(plot_df).encode(x='timestamp:T')\\nline = base.mark_line(color='#1f77b4').encode(y='value:Q')\\npred_chart = alt.Chart(plot_df[plot_df['predicted']==1]).mark_point(color='orange', size=30, opacity=0.75).encode(x='timestamp:T', y='value:Q')\\nlayers = [line, pred_chart]\\nif show_true:\\n    true_chart = alt.Chart(plot_df[plot_df['is_anomaly']==1]).mark_point(color='red', size=50, opacity=0.75).encode(x='timestamp:T', y='value:Q')\\n    layers.append(true_chart)\\nchart = alt.layer(*layers).resolve_scale(y='shared').properties(height=420)\\nst.altair_chart(chart, use_container_width=True)\\n\\nst.download_button('Download data (CSV)', data=df.to_csv(index=False), file_name='anomaly_results.csv', mime='text/csv')\\n\")\n",
    "print('Created streamlit_app.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03946d6",
   "metadata": {},
   "source": [
    "## 8) Launch Streamlit (Binder)\n",
    "Run the cell below, then open: **[/proxy/8501/](/proxy/8501/)**\n",
    "\n",
    "> If the app returns 404 at first, wait ~10–20 seconds and refresh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78af16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, subprocess, time\n",
    "print('Starting Streamlit on port 8501...')\n",
    "proc = subprocess.Popen([sys.executable, '-m', 'streamlit', 'run', 'streamlit_app.py', '--server.port', '8501', '--server.address', '0.0.0.0'])\n",
    "for i in range(10):\n",
    "    time.sleep(1)\n",
    "    print('.', end='')\n",
    "print('\n",
    "Open the app at /proxy/8501/')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
